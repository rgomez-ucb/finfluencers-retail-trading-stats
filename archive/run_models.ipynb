{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2874282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "final_merged_data = pd.read_csv(\"final_merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "983e8bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'net_sentiment', 'stock', 'sofr_Rate Type', 'sofr_Rate (%)',\n",
       "       'sofr_1st Percentile (%)', 'sofr_25th Percentile (%)',\n",
       "       'sofr_75th Percentile (%)', 'sofr_99th Percentile (%)',\n",
       "       'sofr_Volume ($Billions)', 'sofr_Target Rate From (%)',\n",
       "       'sofr_Target Rate To (%)', 'sofr_Intra Day - Low (%)',\n",
       "       'sofr_Intra Day - High (%)', 'sofr_Standard Deviation (%)',\n",
       "       'sofr_30-Day Average SOFR', 'sofr_90-Day Average SOFR',\n",
       "       'sofr_180-Day Average SOFR', 'sofr_SOFR Index',\n",
       "       'sofr_Revision Indicator (Y/N)', 'sofr_Footnote ID', 'unemp_UNEMPLOY',\n",
       "       'vix_VIXCLS', 'fomc_month', 'fomc_raw_date_text', 'fomc_year',\n",
       "       'aapl_Open', 'aapl_High', 'aapl_Low', 'aapl_Close', 'aapl_Adj Close',\n",
       "       'aapl_Volume', 'amzn_Open', 'amzn_High', 'amzn_Low', 'amzn_Close',\n",
       "       'amzn_Adj Close', 'amzn_Volume', 'fed_DFEDTARU', 'fed_rate_change',\n",
       "       'fed_action'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e839c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                             datetime64[ns]\n",
      "net_sentiment                           float64\n",
      "stock                                    object\n",
      "sofr_Rate Type                           object\n",
      "sofr_Rate (%)                           float64\n",
      "sofr_1st Percentile (%)                 float64\n",
      "sofr_25th Percentile (%)                float64\n",
      "sofr_75th Percentile (%)                float64\n",
      "sofr_99th Percentile (%)                float64\n",
      "sofr_Volume ($Billions)                 float64\n",
      "sofr_Target Rate From (%)               float64\n",
      "sofr_Target Rate To (%)                 float64\n",
      "sofr_Intra Day - Low (%)                float64\n",
      "sofr_Intra Day - High (%)               float64\n",
      "sofr_Standard Deviation (%)             float64\n",
      "sofr_30-Day Average SOFR                float64\n",
      "sofr_90-Day Average SOFR                float64\n",
      "sofr_180-Day Average SOFR               float64\n",
      "sofr_SOFR Index                         float64\n",
      "sofr_Revision Indicator (Y/N)           float64\n",
      "sofr_Footnote ID                        float64\n",
      "unemp_UNEMPLOY                          float64\n",
      "vix_VIXCLS                              float64\n",
      "fomc_month                               object\n",
      "fomc_raw_date_text                       object\n",
      "fomc_year                               float64\n",
      "aapl_Open                                object\n",
      "aapl_High                               float64\n",
      "aapl_Low                                float64\n",
      "aapl_Close                              float64\n",
      "aapl_Adj Close                          float64\n",
      "aapl_Volume                              object\n",
      "amzn_Open                               float64\n",
      "amzn_High                               float64\n",
      "amzn_Low                                float64\n",
      "amzn_Close                              float64\n",
      "amzn_Adj Close                          float64\n",
      "amzn_Volume                              object\n",
      "fed_DFEDTARU                            float64\n",
      "fed_rate_change                         float64\n",
      "fed_action                               object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
      "C:\\Users\\Huawei\\AppData\\Local\\Temp\\ipykernel_47488\\2682829487.py:9: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "df = final_merged_data.copy()\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        df[col] = df[col].astype(str).str.replace(\",\", \"\").str.replace(\"%\", \"\")\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        sample = df[col].dropna().head(20)\n",
    "        if all(s.replace('.', '', 1).isdigit() for s in sample if isinstance(s, str)):\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5e7fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl_Open      float64\n",
      "aapl_Volume    float64\n",
      "amzn_Volume    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "numeric_fix_cols = [\"aapl_Open\", \"aapl_Volume\", \"amzn_Volume\"]\n",
    "\n",
    "for col in numeric_fix_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\")\n",
    "        .str.replace(\"%\", \"\")\n",
    "        .str.strip()\n",
    "    )\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "print(df[numeric_fix_cols].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a96854",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(op, a, b, use_numexpr)\u001b[39m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[32m    241\u001b[39m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:131\u001b[39m, in \u001b[36m_evaluate_numexpr\u001b[39m\u001b[34m(op, op_str, a, b)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     result = \u001b[43m_evaluate_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[39m, in \u001b[36m_evaluate_standard\u001b[39m\u001b[34m(op, op_str, a, b)\u001b[39m\n\u001b[32m     72\u001b[39m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m df = df[df[\u001b[33m'\u001b[39m\u001b[33mVolume\u001b[39m\u001b[33m'\u001b[39m].notna()].copy()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# dependent variable log_volume\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mlog_volume\u001b[39m\u001b[33m'\u001b[39m] = np.log(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVolume\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# independent variable exposure\u001b[39;00m\n\u001b[32m     26\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mexposure\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mnet_sentiment\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:186\u001b[39m, in \u001b[36mOpsMixin.__add__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__add__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__add__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m    100\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m    Get Addition of DataFrame and other, column-wise.\u001b[39;00m\n\u001b[32m    102\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    184\u001b[39m \u001b[33;03m    moose     3.0     NaN\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6135\u001b[39m, in \u001b[36mSeries._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   6133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[32m   6134\u001b[39m     \u001b[38;5;28mself\u001b[39m, other = \u001b[38;5;28mself\u001b[39m._align_for_op(other)\n\u001b[32m-> \u001b[39m\u001b[32m6135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1382\u001b[39m, in \u001b[36mIndexOpsMixin._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   1379\u001b[39m     rvalues = np.arange(rvalues.start, rvalues.stop, rvalues.step)\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     result = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(result, name=res_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[39m, in \u001b[36marithmetic_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    279\u001b[39m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    281\u001b[39m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[32m    282\u001b[39m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     res_values = \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:227\u001b[39m, in \u001b[36m_na_arithmetic_op\u001b[39m\u001b[34m(left, right, op, is_cmp)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    221\u001b[39m         left.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    222\u001b[39m     ):\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[32m    226\u001b[39m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m         result = \u001b[43m_masked_arith_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:182\u001b[39m, in \u001b[36m_masked_arith_op\u001b[39m\u001b[34m(x, y, op)\u001b[39m\n\u001b[32m    179\u001b[39m         mask = np.where(y == \u001b[32m1\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, mask)\n\u001b[32m    181\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m         result[mask] = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrav\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m np.putmask(result, ~mask, np.nan)\n\u001b[32m    185\u001b[39m result = result.reshape(x.shape)  \u001b[38;5;66;03m# 2D compat\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = final_merged_data.copy()\n",
    "\n",
    "# rename the control variables for convenience\n",
    "df.rename(columns={\n",
    "    'vix_VIXCLS': 'vix',\n",
    "    'unemp_UNEMPLOY': 'unemp',\n",
    "    'fed_DFEDTARU': 'fed_rate'\n",
    "}, inplace=True)\n",
    "\n",
    "# choose relevant columns\n",
    "df['Volume'] = df.apply(\n",
    "    lambda r: r['aapl_Volume'] if r['stock']=='AAPL' else r['amzn_Volume'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# delete rows with NA volume\n",
    "df = df[df['Volume'].notna()].copy()\n",
    "\n",
    "# dependent variable log_volume\n",
    "df['log_volume'] = np.log(df['Volume'] + 1)\n",
    "\n",
    "# independent variable exposure\n",
    "df['exposure'] = df['net_sentiment']\n",
    "\n",
    "# time processing\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "df = df.sort_values(['stock','date'])\n",
    "\n",
    "# lagged variables\n",
    "df['exposure_lag1'] = df.groupby('stock')['exposure'].shift(1)\n",
    "df['log_volume_lag1'] = df.groupby('stock')['log_volume'].shift(1)\n",
    "\n",
    "# drop NA rows\n",
    "df = df.dropna(subset=['log_volume','exposure'])\n",
    "\n",
    "# =============== IV ===============\n",
    "def run_ols(formula, data, cluster=None):\n",
    "    m = smf.ols(formula=formula, data=data).fit()\n",
    "    if cluster is not None:\n",
    "        m = m.get_robustcov_results(cov_type='cluster', groups=data[cluster])\n",
    "    else:\n",
    "        m = m.get_robustcov_results(cov_type='HC1')\n",
    "    print(m.summary())\n",
    "    return m\n",
    "\n",
    "\n",
    "# =============== SINGLE STOCK ANALYSIS ===============\n",
    "\n",
    "def analyze_stock(stock):\n",
    "    print(f\"\\n================ 分析 {stock} ================\\n\")\n",
    "    sub = df[df['stock']==stock].dropna(subset=['log_volume','exposure'])\n",
    "\n",
    "    # baseline OLS\n",
    "    print(\">> Baseline OLS:\")\n",
    "    run_ols(\n",
    "        \"log_volume ~ exposure + vix + unemp + fed_rate\",\n",
    "        sub\n",
    "    )\n",
    "\n",
    "    # add lagged vars\n",
    "    print(\"\\n>> OLS + lagged vars:\")\n",
    "    run_ols(\n",
    "        \"log_volume ~ exposure + exposure_lag1 + log_volume_lag1 + vix + unemp + fed_rate\",\n",
    "        sub\n",
    "    )\n",
    "\n",
    "    #fixed effects\n",
    "    print(\"\\n>> Time FE:\")\n",
    "    run_ols(\n",
    "        \"log_volume ~ exposure + exposure_lag1 + log_volume_lag1 + vix + unemp + fed_rate + C(date_str)\",\n",
    "        sub\n",
    "    )\n",
    "\n",
    "analyze_stock(\"AAPL\")\n",
    "analyze_stock(\"AMZN\")\n",
    "\n",
    "# =============== mergerd pooled analysis ===============\n",
    "\n",
    "print(\"\\n================ Merged Pooled Analysis ================\\n\")\n",
    "\n",
    "run_ols(\n",
    "    \"\"\"\n",
    "    log_volume ~ exposure + exposure_lag1 + log_volume_lag1\n",
    "                 + vix + unemp + fed_rate\n",
    "                 + C(stock) + C(date_str)\n",
    "    \"\"\",\n",
    "    df,\n",
    "    cluster=\"stock\"\n",
    ")\n",
    "\n",
    "# add interaction term for AMZN\n",
    "df[\"is_amzn\"] = (df[\"stock\"]==\"AMZN\").astype(int)\n",
    "\n",
    "run_ols(\n",
    "    \"\"\"\n",
    "    log_volume ~ exposure + exposure:is_amzn\n",
    "                 + exposure_lag1 + log_volume_lag1\n",
    "                 + vix + unemp + fed_rate\n",
    "                 + C(stock) + C(date_str)\n",
    "    \"\"\",\n",
    "    df,\n",
    "    cluster=\"stock\"\n",
    ")\n",
    "\n",
    "\n",
    "# =============== 5. DiD===============\n",
    "\n",
    "def run_did(treat_stock, event_date):\n",
    "    print(f\"\\n=============== DiD: treat = {treat_stock}, event_date = {event_date} ===============\\n\")\n",
    "\n",
    "    dd = df.copy()\n",
    "    event_date = pd.to_datetime(event_date)\n",
    "\n",
    "    dd[\"treat\"] = (dd[\"stock\"] == treat_stock).astype(int)\n",
    "    dd[\"post\"] = (dd[\"date\"] >= event_date).astype(int)\n",
    "    dd[\"did\"] = dd[\"treat\"] * dd[\"post\"]\n",
    "\n",
    "    run_ols(\n",
    "        \"\"\"\n",
    "        log_volume ~ treat + post + did\n",
    "                     + exposure + exposure_lag1 + log_volume_lag1\n",
    "                     + vix + unemp + fed_rate\n",
    "                     + C(stock) + C(date_str)\n",
    "        \"\"\",\n",
    "        dd,\n",
    "        cluster=\"stock\"\n",
    "    )\n",
    "\n",
    "# change the event date as needed\n",
    "event = \"2020-03-01\"\n",
    "\n",
    "run_did(\"AAPL\", event)\n",
    "run_did(\"AMZN\", event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae312cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'stock', 'sofr_Rate Type', 'fomc_month', 'fomc_raw_date_text',\n",
      "       'aapl_Open', 'aapl_Volume', 'amzn_Volume', 'fed_action', 'Volume'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.select_dtypes(include=\"object\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "826ba5f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Volume'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Volume'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m numeric_object_cols = [\u001b[33m\"\u001b[39m\u001b[33maapl_Open\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maapl_Volume\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mamzn_Volume\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mVolume\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_object_cols:\n\u001b[32m      8\u001b[39m     df[col] = (\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m         .astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     11\u001b[39m         .str.replace(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, regex=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m         .str.replace(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, regex=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     13\u001b[39m         .str.replace(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, regex=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     14\u001b[39m         .replace(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     15\u001b[39m     )\n\u001b[32m     17\u001b[39m     df[col] = pd.to_numeric(df[col], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[numeric_object_cols].dtypes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Huawei\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Volume'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = final_merged_data.copy()\n",
    "\n",
    "numeric_object_cols = [\"aapl_Open\", \"aapl_Volume\", \"amzn_Volume\", \"Volume\"]\n",
    "\n",
    "for col in numeric_object_cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .str.replace(\" \", \"\", regex=False)\n",
    "        .str.replace(\"-\", \"\", regex=False)\n",
    "        .replace(\"\", None)\n",
    "    )\n",
    "\n",
    "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "print(df[numeric_object_cols].dtypes)\n",
    "print(df[numeric_object_cols].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
